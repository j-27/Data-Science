{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a0cb57",
   "metadata": {},
   "source": [
    "Text Analytics on online content.\n",
    "\n",
    "\n",
    "# Objective\n",
    "\n",
    "The objective of this assignment is to extract textual data articles from the given URL and perform text analysis to compute variables that are explained below. \n",
    "\n",
    "# Data Extraction\n",
    "\n",
    "Input.xlsx\n",
    "\n",
    "For each of the articles, given in the input.xlsx file, extract the article text and save the extracted article in a text file with URL_ID as its file name.\n",
    "\n",
    "While extracting text, please make sure your program extracts only the article title and the article text. It should not extract the website header, footer, or anything other than the article text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a95931",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install newspaper3k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebd60742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/javinkaundal/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/javinkaundal/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/javinkaundal/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/javinkaundal/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/javinkaundal/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8c0083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/javinkaundal/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2aed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212f5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e1074d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>https://insights.blackcoffer.com/how-are-genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-ai-use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>https://insights.blackcoffer.com/benefits-of-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>https://insights.blackcoffer.com/how-big-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-ai-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0       1  https://insights.blackcoffer.com/how-is-login-...\n",
       "1       2  https://insights.blackcoffer.com/how-does-ai-h...\n",
       "2       3  https://insights.blackcoffer.com/ai-and-its-im...\n",
       "3       4  https://insights.blackcoffer.com/how-do-deep-l...\n",
       "4       5  https://insights.blackcoffer.com/how-artificia...\n",
       "5       6  https://insights.blackcoffer.com/how-are-genet...\n",
       "6       7  https://insights.blackcoffer.com/how-is-ai-use...\n",
       "7       8  https://insights.blackcoffer.com/benefits-of-b...\n",
       "8       9  https://insights.blackcoffer.com/how-big-data-...\n",
       "9      10  https://insights.blackcoffer.com/how-will-ai-m..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cde809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfb4d774",
   "metadata": {},
   "source": [
    "We would derive the text content from each URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7988651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c24462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://insights.blackcoffer.com/ai-and-its-impact-on-the-fashion-industry/'\n",
    "article = Article(url, language=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd76874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download() \n",
    "article.parse() \n",
    "article.nlp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216bf215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Title:\n",
      "AI and its impact on the Fashion Industry\n",
      "\n",
      "\n",
      "Article Text:\n",
      "If you were a fan of the 90’s film Clueless back in the day, then you’ll remember the protagonist, Cher Horowitz’s amazing virtual wardrobe. She used it to browse her clothing and choose a perfectly coordinated ensemble. This virtual application, which was just the brainchild of a writer wanting to make the protagonist look rich, fashionable, and ahead of her time, ignited a buzz and prospected having an automated style device to make everyday dress-up fun and engagingly time-saving.\n",
      "\n",
      "Times have changed and technological advancement today is transforming everything from probabilities to possibilities. We are in the era where, machines not just facilitate our tasks and demands but rather suggest, forecasts, and analyze thus making lives simpler and smarter.\n",
      "\n",
      "With the advent of technology, style suggestions are just a fraction of the big picture that AI has painted in the fashion industry today.\n",
      "\n",
      "What is AI?\n",
      "\n",
      "Artificial intelligence is the creation of computer programs capable of performing activities and solving issues that would normally need human intelligence. AI has surged across a variety of industries, with the potential to transform businesses through creative technologies and more effective operational processes.\n",
      "\n",
      "At first, AI automation did not appear to be an appealing tool for fashion leaders to use in an industry focused on creative ability and expression. However, as we enter the hyper-digital era, these apps have the potential to revolutionize enterprises and generate considerable industry growth when compared to competitors that use traditional approaches.\n",
      "\n",
      "Some of the most well-known brands in the business are now investing in algorithms that assist buyers to choose designs. A slew of AI-based start-ups is also assisting everyone from retailers to customers in removing the guesswork from the equation.\n",
      "\n",
      "Impact on fashion\n",
      "\n",
      "This article examines how artificial intelligence has impacted key areas of the fashion industry, as well as explores brands that have benefited from its use.\n",
      "\n",
      "AI in Apparel designing\n",
      "\n",
      "Fashion firms are utilizing technology to better understand client wants and produce better garments thanks to more sophisticated data collection.\n",
      "\n",
      "Tommy Hilfiger pioneered the “Reimagine Retail” project, which trains fashion designers with AI design skills in collaboration with IBM. As a result, fashion students could master a variety of technical skills such as natural language processing (NLP) or computer vision. Fashion students could learn from thousands of fashion-related photos using AI, which increased their inventiveness and shortened lead times for the fashion firm.\n",
      "\n",
      "AI in the Manufacturing process\n",
      "\n",
      "Fashion brands are now able to identify fast-changing fashion trends and get the latest fashion accessories to store shelves faster than the “traditional” fashion shop, thanks to AI and machine learning capabilities. As a result, prominent fashion brands such as Zara, Top Shop, and H&M can provide immediate gratification to retail customers by identifying seasonal trends and producing the appropriate quantity of the current items.\n",
      "\n",
      "AI in Logistics\n",
      "\n",
      "AI in inventory and supply chain management helps to speed up processes by optimizing routes and lowering logistics and shipping costs. Companies use AI to automate logistics and supply chain procedures for speedier delivery or to locate alternate routes for vehicles that have been detoured due to unanticipated situations like bad weather or road construction.\n",
      "\n",
      "Owing to lockdown, major fashion firms had to rethink their go-to-market strategy overnight, with actual brick-and-mortar stores closed and people staying away from shopping malls. Myntra finds itself in a unique position to assist them.\n",
      "\n",
      "Myntra moved its whole data infrastructure, including supply chain management, inventory, and website capabilities, to Microsoft Azure just before the pandemic. Apart from giving Myntra the flexibility to respond to demand spikes, Azure’s built-in Machine Learning technologies sped up the development of advanced analytics capabilities, allowing them to better understand their customers.\n",
      "\n",
      "AI in Fashion Retail\n",
      "\n",
      "In retail, AI and machine learning are also providing an automated solution to monitor customer activities while shopping and visualize their sentiments to learn what products they prefer to buy and what products they ignore.\n",
      "\n",
      "AI can also track traffic in retail stores or record consumer shopping experiences, with the option of receiving feedback on how their experience was while shopping at the store, allowing them to enhance their services.\n",
      "\n",
      "Uniqlo has AI-powered UMood kiosks that offer clients a selection of products and use neurotransmitters to assess their reaction to color and style. The kiosk then makes product recommendations based on each person’s reactions. Customers don’t even need to press a button for the system to know how they feel about each item; their brain signals are plenty.\n",
      "\n",
      "AI Fashion Stylist — Styling the Fashion Accessories\n",
      "\n",
      "Furthermore, AI in fashion is enabling each of us to find those elusive perfect garments that suit our body types and fashion preferences.\n",
      "\n",
      "These AI-enabled garments and ensembles are personalized to the user’s style, body type, colors, and current fashion trends, as well as different situations and weather.\n",
      "\n",
      "iLUK is an AI-based personal stylist that uses Computer Vision and 3D Reconstruction technology at its core to provide technology-based personal styling. It’s shaped like a pod that will be placed in a store.\n",
      "\n",
      "AI in Fast Fashion with Smart Mirror\n",
      "\n",
      "Similarly, a smart mirror driven by AI is being utilized by a company to streamline consumers’ shopping experiences by allowing them to virtually visualize how items would appear on them without having to put them on their bodies.\n",
      "\n",
      "The AI smart mirror with touch screen glasses is mounted in the changing room of retail stores and relays information on whether or not a person is inside. Customers can also use this mirror to try on other sizes and colors, as well as receive tailored mix-and-match alternatives to complete the appearance.\n",
      "\n",
      "Van Heusen designed a storage space that includes a “Virtual Trial” mirror that allows customers to view how clothes might appear on them by scanning the item’s barcode and stepping in front of the mirror while virtual clothing is projected onto their reflection.\n",
      "\n",
      "AI in Ecommerce\n",
      "\n",
      "In the same way that AI is revolutionizing retail fashion stores, AI is revolutionizing online purchasing and E-commerce. While browsing or searching for fashion goods on e-commerce sites, AI suggests additional items that are similar to what you’re looking for based on your color preferences, budget, and other factors. It analyses your search history data and suggests more relevant stuff you should look at.\n",
      "\n",
      "Amazon has undoubtedly transformed the online shopping experience with its AI-powered product suggestion engine. Amazon is implementing an AI-enabled fashion designer algorithm that can create clothing by mimicking the design styles of several popular garments and applying them to a new garment. The Echo Look fashion assistant, which uses machine learning to deliver personalized recommendations, is Amazon’s other use case.\n",
      "\n",
      "AI in Visual Search — To Find the Products Using Camera\n",
      "\n",
      "AI-based visual search technology is now employed by E-commerce stores to comprehend the content and context of these photographs and produce a list of related results. You can capture an object using your camera and then search for it online. Retailers can use AI-enabled computer vision-based visual search technology to propose thematically or aesthetically relevant items to customers in a way that would be difficult to do with only a word query.\n",
      "\n",
      "Neiman Marcus, a high-end department store, employs artificial intelligence to make it easier for shoppers to locate things. The Snap. Find. Shop. the app allows users to photograph items they encounter while out and about, and then search Neiman Marcus’ inventory for the same or a comparable item.\n",
      "\n",
      "AI in Fashion and Sustainability\n",
      "\n",
      "One of the most damaging businesses on the earth is the fashion industry. Artificial Intelligence can be used in conjunction with Machine Learning, Deep Learning, Natural Language Processing, Visual Recognition, and Data Analytics to reduce trend prediction errors and more precisely forecast patterns, leading to fewer garments being manufactured and subsequently underutilized.\n",
      "\n",
      "The H&M Group is using “Amplified Intelligence,” which combines analytics and AI with human intelligence.\n",
      "\n",
      "Using artificially intelligent technologies, H&M is enhancing its ability to recognize trends and organize logistics, as well as minimizing the frequency of discounted deals and large amounts of unsold goods.\n",
      "\n",
      "Though intelligence per se is artificial, nevertheless is likely to have an earnest impact, both positive and negative:\n",
      "\n",
      "The fashion dilemma\n",
      "\n",
      "Apparel manufacture is a labor-intensive industry in the fashion industry. AI-enabled machines and robots can perfectly stitch fabrics while also detecting fabric flaws and providing quality assurance to ensure that the actual design hues will match the new colors.\n",
      "\n",
      "In nations like Bangladesh, where the garment industry accounts for 80% of the GDP, this will have a significant influence on the labor force in the long run. It is already feeling the heat from these specialized AI-based devices, thus jeopardizing the jobs of breadwinners.\n",
      "\n",
      "AI should not be viewed as a rival, but rather as a collaborator. The cost and ethics of AI are currently preventing us from progressing. We must be careful not to use technology to increase inequity or exacerbate social injustice. We also need to find a balance and integrate humanity into the machines we’re constructing in the future.\n",
      "\n",
      "Virtual wonderland\n",
      "\n",
      "“We are being monitored and classified by AI in portions of our lives that were not previously watched,” says Sophie Hackford, a futurist and keynote speaker. She wonders if we’ve built the “wrong” internet. We created it intending to monetize our viewers in mind, rather than the dynamic knowledge-sharing area that Tim Berners-Lee envisioned at the start.” She believes that in the future, we will be much more selective in how we obtain information, and that “bots” would be critical in meeting our requirements. As a result, the gains will come at the expense of our privacy.\n",
      "\n",
      "As numerous as AI’s advantages are, it is impossible to ignore the difficult issues it brings. With everything being data-driven, there is a pressing need to establish boundaries to build a shared ecosystem that benefits both businesses and the general public.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Finding a wise balance between physical stores and online stores will continue to be a crucial issue in an industry where brick-and-mortar retail locations are still an important element of the sector’s approach to business.\n",
      "\n",
      "The usefulness of chatbots aimed at improving online and in-store product navigation shows significant promise for preserving customer attention and use in the near term. We expect consumers to become accustomed to these capabilities over time, and the field to become more competitive as AI becomes more broadly applied, as prominent brands set the tone with their usage of AI.\n",
      "\n",
      "It’s too early to tell how these AI applications will affect earnings and cost savings because prominent fashion firms are still in the early stages of AI implementation. However, there will be a learning curve as corporations figure out how consumers react to these innovation efforts, which could have a direct influence on sales.\n",
      "\n",
      "Blackcoffer Insights 33: Lakshman Upadhyay and Prabhlin Kaur Matta, Welingkar Institute of M D R, Mumbai\n",
      "\n",
      "\n",
      "Article Summary:\n",
      "Impact on fashionThis article examines how artificial intelligence has impacted key areas of the fashion industry, as well as explores brands that have benefited from its use.\n",
      "AI Fashion Stylist — Styling the Fashion AccessoriesFurthermore, AI in fashion is enabling each of us to find those elusive perfect garments that suit our body types and fashion preferences.\n",
      "AI in EcommerceIn the same way that AI is revolutionizing retail fashion stores, AI is revolutionizing online purchasing and E-commerce.\n",
      "AI in Fashion and SustainabilityOne of the most damaging businesses on the earth is the fashion industry.\n",
      "Though intelligence per se is artificial, nevertheless is likely to have an earnest impact, both positive and negative:The fashion dilemmaApparel manufacture is a labor-intensive industry in the fashion industry.\n",
      "\n",
      "\n",
      "Article Keywords:\n",
      "['technology', 'learning', 'impact', 'retail', 'shopping', 'ai', 'stores', 'search', 'fashion', 'industry', 'intelligence']\n"
     ]
    }
   ],
   "source": [
    "print(\"Article Title:\") \n",
    "print(article.title) \n",
    "print(\"\\n\") \n",
    "print(\"Article Text:\") \n",
    "print(article.text) \n",
    "print(\"\\n\") \n",
    "print(\"Article Summary:\") \n",
    "print(article.summary) \n",
    "print(\"\\n\") \n",
    "print(\"Article Keywords:\")\n",
    "print(article.keywords) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7441b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(url):\n",
    "    \n",
    "    url1 = url\n",
    "    article = Article(url1, language=\"en\")\n",
    "    \n",
    "    article.download() \n",
    "    article.parse() \n",
    "    article.nlp()\n",
    "    \n",
    "    return article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01eb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1k/qxj7t9890x9_tkxj_62661f00000gn/T/ipykernel_69753/869050490.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['URL_ID'][i] = get_text(df['URL'][i])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df)):\n",
    "    df['URL_ID'][i] = get_text(df['URL'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "314f7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'URL_ID':'Text'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d507ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When people hear AI they often think about sen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-login-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With increasing computing power and more data,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-does-ai-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you were a fan of the 90’s film Clueless ba...</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-its-im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Understanding exactly how data is ingested, an...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-do-deep-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From the stone age to the modern world, from h...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-artificia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial intelligence (AI) is the developmen...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-are-genet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Artificial intelligence (AI) is the most impor...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-is-ai-use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“In God we trust, all others must bring data.”...</td>\n",
       "      <td>https://insights.blackcoffer.com/benefits-of-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big data refers to large sets of unstructured,...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-big-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Artificial intelligence (AI) is intelligence d...</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-ai-m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  When people hear AI they often think about sen...   \n",
       "1  With increasing computing power and more data,...   \n",
       "2  If you were a fan of the 90’s film Clueless ba...   \n",
       "3  Understanding exactly how data is ingested, an...   \n",
       "4  From the stone age to the modern world, from h...   \n",
       "5  Artificial intelligence (AI) is the developmen...   \n",
       "6  Artificial intelligence (AI) is the most impor...   \n",
       "7  “In God we trust, all others must bring data.”...   \n",
       "8  Big data refers to large sets of unstructured,...   \n",
       "9  Artificial intelligence (AI) is intelligence d...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://insights.blackcoffer.com/how-is-login-...  \n",
       "1  https://insights.blackcoffer.com/how-does-ai-h...  \n",
       "2  https://insights.blackcoffer.com/ai-and-its-im...  \n",
       "3  https://insights.blackcoffer.com/how-do-deep-l...  \n",
       "4  https://insights.blackcoffer.com/how-artificia...  \n",
       "5  https://insights.blackcoffer.com/how-are-genet...  \n",
       "6  https://insights.blackcoffer.com/how-is-ai-use...  \n",
       "7  https://insights.blackcoffer.com/benefits-of-b...  \n",
       "8  https://insights.blackcoffer.com/how-big-data-...  \n",
       "9  https://insights.blackcoffer.com/how-will-ai-m...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf101e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/javinkaundal/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73b213",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60847f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b94f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(text):\n",
    "\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ',text)  \n",
    "    review = review.lower()                    \n",
    "    review = review.split()\n",
    "    \n",
    "    review = [word for word in review if not word in stopwords.words('english')]   \n",
    "    review = ' '.join(review)\n",
    "    return review\n",
    "\n",
    "\n",
    "df['Transform_Text'] = df['Text'].apply(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['word_counts'] = df['Transform_Text'].apply(lambda x: len(str(x).split()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43046bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d60324",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nltk.sent_tokenize(df['Text'][0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd065899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average number of words per sentence'] = np.nan\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['average number of words per sentence'][i] = df['word_counts'][i]/len(nltk.sent_tokenize(df['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d155f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1d32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ed03315",
   "metadata": {},
   "source": [
    "# Average Word Length\n",
    "\n",
    "\n",
    "Average Word Length is calculated by the formula:\n",
    "    \n",
    "( Sum of the total number of characters in each word ) / ( Total number of words )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34028754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(x):\n",
    "    s = x.split()\n",
    "    x = ''.join(s)\n",
    "    return len(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e20965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chara_count'] = df['Transform_Text'].apply(lambda x: char_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1417dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff5c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['average word length'] = np.nan\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['average word length'][i] = df['chara_count'][i]/df['word_counts'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb832e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24881903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d00ed3c",
   "metadata": {},
   "source": [
    "# SYLLABLE COUNT\n",
    "\n",
    "We count the number of Syllables in each word of the text by counting the vowels present in each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846352ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428df636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc932be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(x):\n",
    "    v = []\n",
    "    d = {}\n",
    "    for i in x:\n",
    "        if i in \"aeiou\":\n",
    "            v.append(i)\n",
    "            d[i] = d.get(i,0)+1     \n",
    "            \n",
    "    k = []\n",
    "    for i in d:\n",
    "        k.append(d[i])\n",
    "    print(d)\n",
    "    print(v)  \n",
    "    print(k)\n",
    "    print(np.sum(k))\n",
    "        \n",
    "    \n",
    "g = 'bore i am gone to london in england britian uk'\n",
    "\n",
    "syllable_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8541dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8975f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(x):\n",
    "    v = []\n",
    "    d = {}\n",
    "    for i in x:\n",
    "        if i in \"aeiou\":\n",
    "            v.append(i)\n",
    "            d[i] = d.get(i,0)+1\n",
    "            \n",
    "    k = []\n",
    "    for i in d:\n",
    "        k.append(d[i])\n",
    "\n",
    "    return np.sum(k)\n",
    "\n",
    "g = h['Transform_Text'][1]\n",
    "\n",
    "syllable_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff21ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d33be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['syllable count'] = df['Transform_Text'].apply(lambda x: syllable_count(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcde7e80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ffdda03",
   "metadata": {},
   "source": [
    "# COMPLEX Word Count\n",
    "\n",
    "Complex words are words in the text that contain more than two Syllables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cab496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import  Counter\n",
    "\n",
    "def complex_word_count(x):\n",
    "    \n",
    "    syllable = 'aeiou'\n",
    "    \n",
    "    t = x.split()\n",
    "    \n",
    "    v = []\n",
    "    \n",
    "    for i in t:\n",
    "        words = i.split()\n",
    "        c=Counter()\n",
    "        \n",
    "        for word in words:\n",
    "            c.update(set(word))\n",
    "\n",
    "        n = 0\n",
    "        for a in c.most_common():\n",
    "            if a[0] in syllable:\n",
    "                if a[1] >= 2:\n",
    "                    n += 1\n",
    "                \n",
    "        m = 0\n",
    "        p = []\n",
    "        for a in c.most_common():\n",
    "            if a[0] in syllable:\n",
    "                p.append(a[0])\n",
    "        if len(p) >= 2:\n",
    "            m += 1\n",
    "        \n",
    "        if n >= 1 or m >= 1:\n",
    "            v.append(i)\n",
    "            \n",
    "    return len(v) \n",
    "\n",
    "g = h['Transform_Text'][1]\n",
    "\n",
    "complex_word_count(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8097f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d682973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complex_count'] = np.nan\n",
    "\n",
    "df['complex_count'] = df['Transform_Text'].apply(lambda x: complex_word_count(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad55ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "477aa6a8",
   "metadata": {},
   "source": [
    "# Analysis of Readability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75245957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence length'] = np.nan\n",
    "df['Average Sentence Length'] = np.nan\n",
    "df['Percentage of Complex words'] = np.nan\n",
    "df['Fog Index'] = np.nan\n",
    "\n",
    "\n",
    "for i in range(0,len(df)):\n",
    "    \n",
    "    df['sentence length'][i]  =   len(nltk.sent_tokenize(df['Text'][i]))\n",
    "    df['Average Sentence Length'][i] = df['word_counts'][i]/df['sentence length'][i]\n",
    "    df['Percentage of Complex words'][i] = df['complex_count'][i]/df['word_counts'][i] \n",
    "    df['Fog Index'][i] = 0.4 * (df['Average Sentence Length'][i] + df['Percentage of Complex words'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6244cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1bbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491f016b",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYSIS\n",
    "\n",
    "Sentimental analysis is the process of determining whether a piece of writing is positive, negative or neutral.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccb321d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv('sentiment dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdb42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = sentiment[['Word','Negative','Positive']]\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb10bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = ['ZYGOTIC','BAD','DONE','EXCELLENT','WORSE']\n",
    "\n",
    "negative = 0\n",
    "positive = 0\n",
    "\n",
    "for i in dfs['Word']:\n",
    "    if i in f:\n",
    "        if dfs[dfs['Word']==i].Negative.any() == True:\n",
    "            negative += 1\n",
    "        if dfs[dfs['Word']==i].Positive.any() == True:                # CHECKING\n",
    "            positive += 1\n",
    "            \n",
    "print(negative),\n",
    "print(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f375db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bd5b7bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a200ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a667221",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.dropna()\n",
    "dfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4272e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'the good man'\n",
    "w.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['word_lower'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f81d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "        dfs['word_lower'][i] = dfs['Word'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50742,len(dfs)):\n",
    "        dfs['word_lower'][i] = dfs['Word'][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['word_lower'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69831ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fefbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82bbfc79",
   "metadata": {},
   "source": [
    "# Positive Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f8dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def positive(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    positive = 0\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Positive.any() == True:\n",
    "                positive += 1\n",
    "            \n",
    "    return positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce285e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['positive_score'][i] = positive(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_word(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    positive_word = []\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Positive.any() == True:   \n",
    "                positive_word.append(i)\n",
    "            \n",
    "    print(positive_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['positive_word'] = np.nan\n",
    "\n",
    "for i in range(1):\n",
    "    df['positive_word'][i] = positive_word(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc3dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('positive_word',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf5f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d3d0041",
   "metadata": {},
   "source": [
    "# NEGATIVE Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_score(x):\n",
    "    \n",
    "    s = x.split()\n",
    "    \n",
    "    negative = 0\n",
    "    \n",
    "    for i in dfs['word_lower']:\n",
    "        if i in s:\n",
    "            if dfs[dfs['word_lower']==i].Negative.any() == True:\n",
    "                negative += 1\n",
    "            \n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['negative_score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['negative_score'][i] = negative_score(df['Transform_Text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d1b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3159d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa4770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf5f9a04",
   "metadata": {},
   "source": [
    "# Polarity Score\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity Score'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['Polarity Score'][i] = (df['positive_score'][i]-df['negative_score'][i])/ ((df['positive_score'][i] + df['negative_score'][i]) + 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598f078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ceb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3dfa05",
   "metadata": {},
   "source": [
    "# SUBJECTIVITY SCORE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6864d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(df['Transform_Text'][1])\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bfa2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(df['Transform_Text'][1]).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac78c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subjectivity'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['subjectivity'][i] = TextBlob(df['Transform_Text'][i]).sentiment[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e2dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acb603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "940074f8",
   "metadata": {},
   "source": [
    "# PERSONAL PRONOUNS \n",
    "\n",
    "To calculate Personal Pronouns mentioned in the text, we use regex to find the counts of the words - “I,” “we,” “my,” “ours,” and “us”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb725d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e750ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'he is the my father'\n",
    "y = nlp(x)\n",
    "\n",
    "for noun in y.noun_chunks:\n",
    "    print(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('he is the my father')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24963b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'PRON':\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6caf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(df['Text'][1])\n",
    "tok = []\n",
    "for token in doc:\n",
    "    if token.pos_ == 'PRON':\n",
    "        tok.append(token)\n",
    "        \n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da744492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'][1] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c48006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4067d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    doc = nlp(df['Text'][i])\n",
    "    tok = []\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'PRON':\n",
    "            tok.append(token)\n",
    "        \n",
    "    df['PERSONAL PRONOUNS'][i] = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be6ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['PERSONAL PRONOUNS'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c6ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedfa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = df[['URL','positive_score','negative_score','Polarity Score','subjectivity','Average Sentence Length','Percentage of Complex words',\n",
    "            'Fog Index','average number of words per sentence','complex_count','word_counts','syllable count','PERSONAL PRONOUNS','average word length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee78f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78081190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a8b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"URL_ID.xlsx\"\n",
    "\n",
    "submit.to_excel(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
